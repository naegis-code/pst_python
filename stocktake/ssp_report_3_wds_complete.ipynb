{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebb731d6",
   "metadata": {},
   "source": [
    "## 01 libary & paramiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c52a47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Files\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pathlib\n",
    "import db_connect\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "import shutil\n",
    "import xlwings as xw\n",
    "\n",
    "# Set parameters\n",
    "bu = 'ssp'\n",
    "date = '20250101'\n",
    "\n",
    "table_stk = 'stk'\n",
    "#table_var = 'var'\n",
    "\n",
    "rpname_stk = 'STK2'\n",
    "#rpname_var = 'VAR2'\n",
    "\n",
    "sheet_name_stk = '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏ô‡∏±‡∏ö'\n",
    "#sheet_name_var = 'variancelocation'\n",
    "\n",
    "column_stk = 'B:Q'\n",
    "#column_var = 'A:V'\n",
    "\n",
    "#connect to database\n",
    "connect_db3 = create_engine(db_connect.db_url_pstdb3)\n",
    "connect_db = create_engine(db_connect.db_url_pstdb)\n",
    "\n",
    "# Set file path\n",
    "user_path = pathlib.Path.home()\n",
    "f_path = user_path / 'Documents' / 'soh' / 'report3' / str.upper(bu) / 'WDS' \n",
    "\n",
    "# ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô Path object ‡πÄ‡∏•‡∏¢\n",
    "excel_files = [\n",
    "    f_path / f for f in os.listdir(f_path)\n",
    "    if f.lower().endswith(('.xls', '.xlsx', '.xlsm')) and os.path.getsize(f_path / f) > 0\n",
    "]\n",
    "\n",
    "print(f\"{len(excel_files)} Files\")\n",
    "\n",
    "# get data from stk db3\n",
    "stk2_db3 = f\"\"\"\n",
    "SELECT distinct\n",
    "    store, cntdate,skutype, rpname,'recheck' as recheck\n",
    "FROM {bu}_{table_stk}_this_year\n",
    "where rpname = '{rpname_stk}'\n",
    "\"\"\"\n",
    "stk2_db3 = pd.read_sql(stk2_db3, connect_db3)\n",
    "\n",
    "# get data from plan db\n",
    "plan_db = f\"\"\"\n",
    "SELECT \n",
    "    stcode as store, cntdate,branch\n",
    "FROM planall2\n",
    "where atype = '3F'\n",
    "    and cntdate >= '{date}'\n",
    "    and bu = '{bu.upper()}'\n",
    "\"\"\"\n",
    "plan_db = pd.read_sql(plan_db, connect_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72da3ff",
   "metadata": {},
   "source": [
    "## 02 rename sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a38b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = xw.App(visible=False)\n",
    "\n",
    "for xls_file in f_path.glob(\"*.xls\"):\n",
    "    xlsx_file = f_path / (xls_file.stem + \".xlsx\")\n",
    "\n",
    "    try:\n",
    "        wb = app.books.open(str(xls_file))\n",
    "        wb.save(str(xlsx_file))\n",
    "        wb.close()\n",
    "        xls_file.unlink()  # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤\n",
    "        print(f\"‚úÖ ‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå ‡πÅ‡∏•‡∏∞ üóëÔ∏è ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö: {xls_file.name} ‚Üí {xlsx_file.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error ‡πÅ‡∏õ‡∏•‡∏á {xls_file.name}: {e}\")\n",
    "\n",
    "for excel_file in excel_files:\n",
    "    try:\n",
    "        wb = app.books.open(str(excel_file))\n",
    "        changed = False\n",
    "\n",
    "        for sheet in wb.sheets:\n",
    "            old_name = sheet.name\n",
    "            new_name = old_name.lower().replace(\" \", \"\")\n",
    "            if new_name != old_name:\n",
    "                sheet.name = new_name\n",
    "                changed = True\n",
    "                print(f\"‚úÖ {excel_file.name}: '{old_name}' ‚ûù '{new_name}'\")\n",
    "\n",
    "        # Save ‡πÄ‡∏õ‡πá‡∏ô .xlsx ‡πÄ‡∏™‡∏°‡∏≠\n",
    "        new_file = excel_file.with_suffix(\".xlsx\")\n",
    "        wb.save(str(new_file))\n",
    "        wb.close()\n",
    "\n",
    "        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô .xls ‚Üí ‡∏•‡∏ö‡∏ó‡∏¥‡πâ‡∏á\n",
    "        if excel_file.suffix.lower() == \".xls\":\n",
    "            excel_file.unlink()\n",
    "\n",
    "        print(f\"üíæ Saved & replaced: {new_file.name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error {excel_file.name}: {e}\")\n",
    "\n",
    "app.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff127d9",
   "metadata": {},
   "source": [
    "## 03 upload STK2 to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc09fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖProcessed & inserted D:\\Users\\prthanap\\Documents\\soh\\report3\\SSP\\WDS\\Report3_SSP_W010137_20250717_0.xlsx with 811 rows to ssp_stk_this_year (1/2)\n",
      "‚úÖProcessed & inserted D:\\Users\\prthanap\\Documents\\soh\\report3\\SSP\\WDS\\Report3_SSP_W012762_20250813_0.xlsx with 2042 rows to ssp_stk_this_year (2/2)\n"
     ]
    }
   ],
   "source": [
    "for file in excel_files:\n",
    "    file_path = os.path.join(f_path, file)\n",
    "    try:\n",
    "        xls = pd.ExcelFile(file_path)\n",
    "        if sheet_name_stk in xls.sheet_names:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet_name_stk, usecols=column_stk, dtype=str,skiprows=5)\n",
    "\n",
    "            file_parts = os.path.splitext(file)[0].split('_')\n",
    "            if len(file_parts) == 5:\n",
    "                cols1, cols2, cols3, cols4, cols5 = file_parts\n",
    "            else:\n",
    "                cols1, cols2, cols3, cols4, cols5 = None, None, None, None, None\n",
    "\n",
    "            column_mapping = {\n",
    "                'CUS_CODE': 'countname',\n",
    "                'DP_CODE': 'dpt',\n",
    "                'PR_CODE': 'sku',\n",
    "                'PR_NAME': 'sku_des',\n",
    "                'PR_BRAND': 'brnnam',\n",
    "                'PR_MODEL': 'catalogue',\n",
    "                'COLOR': 'coldsc',\n",
    "                'PR_SIZE': 'sizdsc',\n",
    "                'Unit Cost': 'cost',\n",
    "                'Unit Retail': 'retail',\n",
    "                'Quantity': 'soh',\n",
    "                'Physical Count': 'qty_count',\n",
    "                'Sum Unit Retail': 'phycnt_rtl',\n",
    "                'Sum Unit Cost': 'physcnt_cst'\n",
    "            }\n",
    "\n",
    "            df = df.rename(columns=column_mapping)\n",
    "\n",
    "            df.columns = df.columns.str.lower()\n",
    "            \n",
    "            \n",
    "            for col in ['cost', 'retail', 'soh', 'qty_count']:\n",
    "                if col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce').round(3)\n",
    "            \n",
    "\n",
    "            df['qty_var'] = df['qty_count'] - df['soh']\n",
    "\n",
    "            df['extrtl_var'] = df['qty_var'] * df['retail']\n",
    "            df['extcst_var'] = df['qty_var'] * df['cost']\n",
    "\n",
    "            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà\n",
    "            df['store'] = cols3\n",
    "            df['cntdate'] = cols4\n",
    "            df['rpname'] = rpname_stk\n",
    "\n",
    "            # ‡∏ñ‡πâ‡∏≤ COUNTNAME ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ (NaN) ‡πÉ‡∏´‡πâ fill ‡∏î‡πâ‡∏ß‡∏¢ '' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô error\n",
    "            df['sku'] = df['sku'].fillna('')\n",
    "\n",
    "            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå ibc ‡πÅ‡∏•‡∏∞ sbc ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å sku\n",
    "            df['ibc'] = df['sku']\n",
    "            df['sbc'] = df['sku']\n",
    "\n",
    "            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå skutype\n",
    "            df['skutype'] = 'Credit'\n",
    "\n",
    "            # join plan db\n",
    "            df = df.merge(plan_db[['store', 'cntdate','branch']],\n",
    "                          on=['store', 'cntdate'],\n",
    "                          how='left')\n",
    "            # keep only rows with branch **not null**\n",
    "            df = df[df['branch'].notna()]\n",
    "\n",
    "            # join stk db3\n",
    "            df = df.merge(stk2_db3[['store', 'cntdate', 'skutype', 'rpname','recheck']],\n",
    "                          on=['store', 'cntdate', 'skutype', 'rpname'],\n",
    "                          how='left')\n",
    "            # keep only rows with recheck **is null**\n",
    "            df = df[df['recheck'].isna()]\n",
    "\n",
    "            df = df.drop(columns=['branch', 'recheck','gp%','amount','sum cost','amount - gp%'])\n",
    "\n",
    "            df.to_sql(f'{bu}_{table_stk}_this_year', connect_db3, if_exists='append', index=False)\n",
    "\n",
    "            xls.close()\n",
    "\n",
    "            # Move processed file to 'Processed' folder\n",
    "            processed_dir = user_path / 'Documents' / 'soh' / 'report3' / 'Processed'\n",
    "            shutil.move(str(file), str(processed_dir / file.name))\n",
    "\n",
    "            print(f\"‚úÖProcessed & inserted {file} with {len(df)} rows to {bu}_{table_stk}_this_year ({excel_files.index(file)+1}/{len(excel_files)})\")\n",
    "        else:\n",
    "            print(f\"‚ùåsheet not found in {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùåError processing {file}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
