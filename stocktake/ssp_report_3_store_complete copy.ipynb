{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebb731d6",
   "metadata": {},
   "source": [
    "## 01 libary & paramiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c52a47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Files\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pathlib\n",
    "import db_connect\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "import shutil\n",
    "\n",
    "# Set parameters\n",
    "bu = 'ssp'\n",
    "date = '20250101'\n",
    "\n",
    "table_stk = 'stk'\n",
    "table_var = 'var'\n",
    "\n",
    "rpname_stk = 'STK2'\n",
    "rpname_var = 'VAR2'\n",
    "\n",
    "sheet_name_stk = 'detailsku'\n",
    "sheet_name_var = 'variancelocation'\n",
    "\n",
    "column_stk = 'A:AC'\n",
    "column_var = 'A:V'\n",
    "\n",
    "#connect to database\n",
    "connect_db3 = create_engine(db_connect.db_url_pstdb3)\n",
    "connect_db = create_engine(db_connect.db_url_pstdb)\n",
    "\n",
    "\n",
    "# Set file path\n",
    "user_path = pathlib.Path.home()\n",
    "f_path = user_path / 'Documents' / 'soh' / 'report3' / str.upper(bu) / 'Store' \n",
    "\n",
    "excel_files = [\n",
    "    f for f in os.listdir(f_path)\n",
    "    if f.lower().endswith(('xls','.xlsx', '.xlsm')) and os.path.getsize(f_path / f) > 0\n",
    "]\n",
    "\n",
    "print(f\"{len(excel_files)} Files\")\n",
    "\n",
    "# get data from stk db3\n",
    "stk2_db3 = f\"\"\"\n",
    "SELECT distinct\n",
    "    store, cntdate,skutype, rpname,'recheck' as recheck\n",
    "FROM {bu}_{table_stk}_this_year\n",
    "where rpname = '{rpname_stk}'\n",
    "\"\"\"\n",
    "stk2_db3 = pd.read_sql(stk2_db3, connect_db3)\n",
    "\n",
    "# get data from plan db\n",
    "plan_db = f\"\"\"\n",
    "SELECT \n",
    "    stcode as store, cntdate,branch\n",
    "FROM planall2\n",
    "where atype = '3F'\n",
    "    and cntdate >= '{date}'\n",
    "    and bu = '{bu.upper()}'\n",
    "\"\"\"\n",
    "plan_db = pd.read_sql(plan_db, connect_db)\n",
    "\n",
    "# get data from var db3\n",
    "var2_db3 = f\"\"\"\n",
    "SELECT distinct\n",
    "    store, cntdate,skutype, rpname,'recheck' as recheck\n",
    "FROM {bu}_{table_var}_this_year\n",
    "where rpname = '{rpname_var}'\"\"\"\n",
    "var2_db3 = pd.read_sql(var2_db3, connect_db3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72da3ff",
   "metadata": {},
   "source": [
    "## 02 rename sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a38b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in excel_files:\n",
    "    file_path = f_path / fname\n",
    "    try:\n",
    "        wb = load_workbook(file_path)\n",
    "        changed = False\n",
    "        for sheet in wb.sheetnames:\n",
    "            new_name = sheet.lower().replace(\" \", \"\")\n",
    "            if new_name != sheet:\n",
    "                wb[sheet].title = new_name\n",
    "                changed = True\n",
    "                print(f\"✅{fname}: '{sheet}' ➝ '{new_name}'\")\n",
    "        if changed:\n",
    "            wb.save(file_path)  # บันทึกทับไฟล์เดิม\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error {fname}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff127d9",
   "metadata": {},
   "source": [
    "## 03 upload STK2 to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc09fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in excel_files:\n",
    "    file_path = os.path.join(f_path, file)\n",
    "    try:\n",
    "        xls = pd.ExcelFile(file_path)\n",
    "        if sheet_name_stk in xls.sheet_names:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet_name_stk, usecols=column_stk, dtype=str)\n",
    "\n",
    "            df.columns = df.columns.str.lower()\n",
    "\n",
    "            file_parts = os.path.splitext(file)[0].split('_')\n",
    "            if len(file_parts) == 5:\n",
    "                cols1, cols2, cols3, cols4, cols5 = file_parts\n",
    "            else:\n",
    "                cols1, cols2, cols3, cols4, cols5 = None, None, None, None, None\n",
    "\n",
    "            # เพิ่มคอลัมน์ใหม่\n",
    "            df['cntdate'] = cols4\n",
    "            df['rpname'] = rpname_stk\n",
    "\n",
    "            # ถ้า COUNTNAME ไม่มีค่า (NaN) ให้ fill ด้วย '' เพื่อป้องกัน error\n",
    "            df['sku'] = df['sku'].fillna('')\n",
    "\n",
    "            # สร้างคอลัมน์ skutype\n",
    "            df['skutype'] = df['countname'].apply(lambda x: 'Credit' if x[1:2] == 'B' else 'Consign')\n",
    "\n",
    "            # กรองตาม STORE\n",
    "            df = df[df['store'] == cols3]\n",
    "\n",
    "            # join plan db\n",
    "            df = df.merge(plan_db[['store', 'cntdate','branch']],\n",
    "                          on=['store', 'cntdate'],\n",
    "                          how='left')\n",
    "            # keep only rows with branch **not null**\n",
    "            df = df[df['branch'].notna()]\n",
    "\n",
    "            # join stk db3\n",
    "            df = df.merge(stk2_db3[['store', 'cntdate', 'skutype', 'rpname','recheck']],\n",
    "                          on=['store', 'cntdate', 'skutype', 'rpname'],\n",
    "                          how='left')\n",
    "            # keep only rows with recheck **is null**\n",
    "            df = df[df['recheck'].isna()]\n",
    "\n",
    "            df = df.drop(columns=['branch', 'recheck'])\n",
    "\n",
    "            df.to_sql(f'{bu}_{table_stk}_this_year', connect_db3, if_exists='append', index=False)\n",
    "\n",
    "            print(f\"✅Processed & inserted {file} with {len(df)} rows to {bu}_{table_stk}_this_year ({excel_files.index(file)+1}/{len(excel_files)})\")\n",
    "        else:\n",
    "            print(f\"❌sheet not found in {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌Error processing {file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94acf07",
   "metadata": {},
   "source": [
    "## 04 upload VAR2 to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70044ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅Processed & inserted Report3_SSP_80034_20250701_0.xlsx with 0 rows to ssp_var_this_year (1/14)\n",
      "✅Processed & inserted Report3_SSP_80053_20250624_0.xlsx with 0 rows to ssp_var_this_year (2/14)\n",
      "✅Processed & inserted Report3_SSP_80093_20250624_0.xlsx with 0 rows to ssp_var_this_year (3/14)\n",
      "✅Processed & inserted Report3_SSP_80101_20250805_0.xlsx with 0 rows to ssp_var_this_year (4/14)\n",
      "✅Processed & inserted Report3_SSP_80136_20250519_0.xlsx with 0 rows to ssp_var_this_year (5/14)\n",
      "✅Processed & inserted Report3_SSP_80137_20250625_0.xlsx with 0 rows to ssp_var_this_year (6/14)\n",
      "✅Processed & inserted Report3_SSP_80204_20250617_0.xlsx with 0 rows to ssp_var_this_year (7/14)\n",
      "✅Processed & inserted Report3_SSP_80226_20250819_0.xlsx with 0 rows to ssp_var_this_year (8/14)\n",
      "✅Processed & inserted Report3_SSP_80249_20250624_0.xlsx with 0 rows to ssp_var_this_year (9/14)\n",
      "✅Processed & inserted Report3_SSP_80303_20250626_0.xlsx with 0 rows to ssp_var_this_year (10/14)\n",
      "✅Processed & inserted Report3_SSP_80312_20250805_0.xlsx with 0 rows to ssp_var_this_year (11/14)\n",
      "✅Processed & inserted Report3_SSP_80360_20250819_0.xlsx with 0 rows to ssp_var_this_year (12/14)\n",
      "✅Processed & inserted Report3_SSP_80376_20250604_0.xlsx with 0 rows to ssp_var_this_year (13/14)\n",
      "✅Processed & inserted Report3_SSP_80380_20250625_0.xlsx with 0 rows to ssp_var_this_year (14/14)\n"
     ]
    }
   ],
   "source": [
    "for file in excel_files:\n",
    "    file_path = os.path.join(f_path, file)\n",
    "    try:\n",
    "        xls = pd.ExcelFile(file_path)\n",
    "        if sheet_name_var in xls.sheet_names:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet_name_var, usecols=column_var, dtype=str)\n",
    "\n",
    "            df.columns = df.columns.str.lower()\n",
    "\n",
    "            file_parts = os.path.splitext(file)[0].split('_')\n",
    "            if len(file_parts) == 5:\n",
    "                cols1, cols2, cols3, cols4, cols5 = file_parts\n",
    "            else:\n",
    "                cols1, cols2, cols3, cols4, cols5 = None, None, None, None, None\n",
    "\n",
    "            # เพิ่มคอลัมน์ใหม่\n",
    "            df['cntdate'] = cols4\n",
    "            df['rpname'] = rpname_var\n",
    "\n",
    "            # ถ้า COUNTNAME ไม่มีค่า (NaN) ให้ fill ด้วย '' เพื่อป้องกัน error\n",
    "            df['sku'] = df['sku'].fillna('')\n",
    "\n",
    "            # สร้างคอลัมน์ skutype\n",
    "            df['skutype'] = df['countname'].apply(lambda x: 'Credit' if x[1:2] == 'B' else 'Consign')\n",
    "\n",
    "            # กรองตาม STORE\n",
    "            df = df[df['store'] == cols3]\n",
    "\n",
    "            # join plan db\n",
    "            df = df.merge(plan_db[['store', 'cntdate','branch']],\n",
    "                          on=['store', 'cntdate'],\n",
    "                          how='left')\n",
    "            # keep only rows with branch **not null**\n",
    "            df = df[df['branch'].notna()]\n",
    "\n",
    "            # join stk db3\n",
    "            df = df.merge(var2_db3[['store', 'cntdate', 'skutype', 'rpname','recheck']],\n",
    "                          on=['store', 'cntdate', 'skutype', 'rpname'],\n",
    "                          how='left')\n",
    "            # keep only rows with recheck **is null**\n",
    "            df = df[df['recheck'].isna()]\n",
    "\n",
    "            df = df.drop(columns=['branch', 'recheck'])\n",
    "\n",
    "            df.to_sql(f'{bu}_{table_var}_this_year', connect_db3, if_exists='append', index=False)\n",
    "\n",
    "            xls.close()\n",
    "\n",
    "            shutil.move(file_path, user_path / 'Documents' / 'soh' / 'report3' / 'Processed' / file)    \n",
    "\n",
    "            print(f\"✅Processed & inserted {file} with {len(df)} rows to {bu}_{table_var}_this_year ({excel_files.index(file)+1}/{len(excel_files)})\")\n",
    "        else:\n",
    "            print(f\"❌sheet not found in {file} ({excel_files.index(file)+1}/{len(excel_files)})\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌Error processing {file}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
